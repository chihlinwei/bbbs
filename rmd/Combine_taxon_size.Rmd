---
title: "Combine Taxon Size data"
author: "Chih-Lin Wei"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

The purpose of this code is to combine multiple spreadsheets of macrofauna or meiofauna size measurements (arranged by taxon) into a single sheet.

```{r}
library(ggplot2)
library(plyr)
library(doBy)
library(readxl)
library(foreach)
library(doSNOW)

large <- theme(legend.title = element_text(size=20),
        legend.text = element_text(size=20),
        strip.text=element_text(size=20),
        axis.title = element_text(size=20),
        axis.text.y = element_text(size=20),
        axis.text.x = element_text(size=20, angle=60, hjust=0.5))

rotate <- theme(axis.text.x = element_text(size=20, angle=60, hjust=0.5))

# dark theme for ggplot
dark <- theme(plot.background = element_rect(colour = 'NA', fill = 'gray10'),
        panel.background = element_rect(colour = 'NA', fill = 'transparent'),
        legend.background = element_rect(colour = 'NA', fill = 'transparent'),
        legend.title = element_text(colour = 'white', size=20),
        legend.text = element_text(colour = 'white', size=20),
        axis.title = element_text(colour = 'white', size=20),
        axis.text = element_text(colour = 'white', size=20),
        axis.ticks = element_line(colour = 'white'),
        panel.border = element_rect(fill = 'NA', colour = 'white'), 
        panel.grid.major = element_line(colour = 'gray30'),
        panel.grid.minor = element_line(colour = 'gray20'))
```

# Observed macrofauna body size

## All macrofauna
* Currently only OR1 1096, 1102, 1114, 1126, 1128 and 1132 (GS1 only) were included in the analysis.
* Only keep intact specimens

```{r, fig.width=10, fig.height=6}
col_types <- c("text", "text", "text", "numeric", "numeric", "text", "text", "text", "text", "text", "text", 
              "numeric", "numeric", "numeric", "numeric", "numeric", "numeric", "text")

mac <- NULL
for(i in 1:15){
  d <- read_excel("../excel/GPSC_macro_size_2020.08.03.xlsx", sheet=i, col_types=col_types)
  mac <- rbind(mac, d)
}
mac <- as.data.frame(mac)

depth <- read_excel("../excel/GPSC_macro_sorting_2020.07.31.xlsx", sheet=1)
mac <- cbind(depth[match(paste(mac$Cruise, mac$Station), paste(depth$Cruise, depth$Station)), c("Region", "Date", "Longitude", "Latitude", "Depth", "Corer", "Area", "Sieve")], mac)
mac$Wt <- mac$Size*(1.13)

depth.bk <- c(200, 400, 600, 800, 1100, 2000, 3700)
depth.lab <- c("200-400", "400-600", "600-800", "800-1100", "1100-2000", "2000-3700")
mac$Depth.zone <- cut(mac$Depth, breaks=depth.bk, labels=depth.lab)

# Split the size data by polychaetes, nematods, harpacticoids, peracarids and others
Category <- as.character(mac$Taxon)
Category[Category=="Amphipoda"|Category=="Cumacea"|Category=="Isopoda"|Category=="Tanaidacea"] <- "Peracarida"
Category[Category=="Oligochaeta"|Category=="Nemertea"|Category=="Sipuncula"|Category=="Aplacophora"|Category=="Ostracoda"] <- "Others"

mac <- cbind(Category, mac)
mac <- subset(mac, Cruise=="OR1_1096"|Cruise=="OR1_1102"|Cruise=="OR1_1114"|Cruise=="OR1_1126"|Cruise=="OR1_1128"|(Cruise=="OR1_1132" & Station=="GS1"))

# Size (complete specimen)
mac_c <- subset(mac, Condition=="C")

# Observed macrofauna sizes
ggplot(data=mac_c, 
       aes(x=log10(Wt), fill=Habitat))+
  geom_density(alpha=0.5)+
  scale_fill_manual(values=c("black", "gray"))+
  facet_wrap(~Cruise)+
  labs(y="Frequency", x=expression(Log[10]~body~size~(mg)))+
  theme_bw() %+replace% large #%+replace% dark
```

## Polychaete only

```{r, fig.width=10, fig.height=6}
# Observed polychaete sizes
ggplot(data=subset(mac_c, Category=="Polychaeta"), 
       aes(x=log10(Wt), fill=Habitat))+
  geom_density(alpha=0.5)+
  scale_fill_manual(values=c("black", "gray"))+
  facet_wrap(~Cruise, scales="free")+
  labs(y="Frequency", x=expression(Log[10]~body~size~(mg)))+
  theme_bw() %+replace% large #%+replace% dark
```
No complete polychaete specimens during cruise 1102 in canyon and only one intact specimen during cruise 1128 at GC1

# Simulated macrofauna body size

Polychaetes and Ophiuroids are easy to break off; therefore, we re-sampled the size data of complete specimen to match to the total numbers of individual in a sample (e.g., polychaete with head and ophiurids with disk).

```{r, fig.width=10, fig.height=6}
# Which taxa has fragment specimen?
unique(subset(mac, Condition!="C")$Taxon)

# How many complete specimens in polychaetes and ophiuroids
# Polychaetes
subset(mac, Taxon=="Polychaeta" & Condition == "C")$Size %>% length / subset(mac, Taxon=="Polychaeta")$Size %>% length
# Ophiuroids
subset(mac, Taxon=="Ophiuroidea" & Condition == "C")$Size %>% length / subset(mac, Taxon=="Ophiuroidea")$Size %>% length

# Size (complete macrofauna specimen)
mac_c <- subset(mac, Condition=="C")
mac_c <- splitBy(~Taxon+Cruise+Station+Deployment+Tube, mac_c)

# Abundance (specimen with head)
mac_a <- subset(mac, !(Condition=="F" | is.na(Condition)))
mac_a <- summaryBy(Wt~Taxon+Cruise+Station+Deployment+Tube, data=mac_a, FUN=length, var.names="Abundance", keep.names=TRUE)

# Average by Cruise/Station and then scale the abundance to 3 multicore tubes
#mac_a <- summaryBy(Abundance~Category+Cruise+Station, data=mac_a, FUN=mean, var.names="Abundance", keep.names=TRUE)
#mac_a$Abundance <- mac_a$Abundance*3

# Total abundce in each sample
sn <- with(mac_a, paste(Taxon, Cruise, Station, Deployment, Tube, sep="|"))
abund <- mac_a[match(names(mac_c), sn),]$Abundance

# Resample the size data (with replacement) by the total abundance in each sample
sample_fun <-
  function(i){
    keep <- sample(1:dim(mac_c[[i]])[1], si=abund[i], replace=TRUE)
    mac_c[[i]][keep,]
  }

# Only Polychaeta and Ophiuroidea needs to be resampled
keep <- grep("Polychaeta|Ophiuroidea", names(mac_c))

# Simulated Polychaeta and Ophiuroidea size data
cl<-makeCluster(4) # change the 4 to your number of CPU cores
registerDoSNOW(cl) # register the SNOW parallel backend with the foreach package
simu <- foreach(i=keep) %dopar% sample_fun(i)
stopCluster(cl) # stop a SNOW cluster

# Replace with the simulated Polychaeta and Ophiuroidea data 
for(i in 1:length(keep)) mac_c[[keep[i]]] <- simu[[i]] 

ggplot(data=ldply(mac_c), 
       aes(x=log10(Wt), fill=Habitat))+
  geom_density(alpha=0.5)+
  scale_fill_manual(values=c("black", "gray"))+
  facet_wrap(~Cruise)+
  labs(y="Frequency", x=expression(Log[10]~body~size~(mg)))+
  theme_bw() %+replace% large #%+replace% dark

mac_s <- ldply(mac_c, .id=NULL)
```

# Observed meiofauna size distribution

## All meiofauna

* Only 100 nematodes were randomly selected to measured body size.

```{r, fig.height=8, fig.width=10}
# Hapacticoid and others
col_types <- c("text", "text", "text", "numeric", "numeric", "numeric", "text","text", "text", "text", "text", "text", "text", "numeric", "numeric", "numeric", "numeric", "text")

mei <- NULL
for(i in 1:3){
  d <- as.data.frame(read_excel("../excel/GPSC_meio_size_2020.08.02.xlsx", sheet=i, col_types=col_types))
  mei <- rbind(mei, d)
}

# Get water depth
mei <- cbind(depth[match(paste(mei$Cruise, mei$Station), paste(depth$Cruise, depth$Station)), c("Region", "Date", "Longitude", "Latitude", "Depth", "Corer", "Area", "Sieve")], mei)
mei$Wt <- mei$Size*(1.13)

depth.bk <- c(200, 400, 600, 800, 1100)
depth.lab <- c("200-400", "400-600", "600-800", "800-1100")
mei$Depth.zone <- cut(mei$Depth, breaks=depth.bk, labels=depth.lab)

# Split the size data by nematods, harpacticoids and others
Category <- as.character(mei$Taxon)
Category[Category!="Nematoda"&Category!="Harpacticoida"] <- "Others"
mei <- splitBy(~Category+Cruise+Station, cbind(Category, mei))
mei <- ldply(mei, .id=NULL)

ggplot(data=mei, 
       aes(x=log(Wt), fill=Habitat))+
  geom_density(alpha=0.5)+
  scale_fill_manual(values=c("black", "gray"))+
  facet_grid(Cruise~Category)+
  labs(y="Frequency", x=expression(Log~body~size~(mg~individual^-1)))+
  theme_bw()%+replace% large #%+replace% dark
```

# Simulated meiofauna body size

Because not all nematode specimens were measured for their sizes, the size distribution of nematodes (from 100 random individuals) were scaled to the total observed abundance by re-sampling the observed size measurements (with replacement).

```{r, fig.height=8, fig.width=10}
# Sorting data
mei_a   <- read_excel("../excel/GPSC_meio_sorting_2016.08.18.xlsx", sheet=2)
Category <- as.character(mei_a$Taxon)
Category[Category=="Copepoda"] <- "Harpacticoida"
Category[Category!="Nematoda" & Category!="Harpacticoida"] <- "Others"
mei_a <- cbind(Category, mei_a)
mei_a <- subset(mei_a, Subcore!="water")

# Match the sample names (tube) in size data to the sample names (tube) in sorting data 
# Extract the total abudance from the sorting data 
sn <- with(mei_a, paste(Category, Cruise, Station, Deployment, Tube, Subcore, sep="|"))
mei_s <- splitBy(~Category+Cruise+Station+Deployment+Tube+Subcore, mei)
abund <- mei_a[match(names(mei_s), sn),]$Abundance

# Resample the size data (with replacement) by the total abundance in each sample
sample_fun <-
  function(i){
    keep <- sample(1:dim(mei_s[[i]])[1], si=abund[i], replace=TRUE)
    mei_s[[i]][keep,]
  }

# Only Nematoda needs to be resampled
kp <- grep("Nematoda", names(mei_s))

# indentify nematode
id <- lapply(mei_s, FUN=function(x)dim(x)[1])%>%unlist%>%as.vector

# Only simulate size data when the numbers of sorted nematodes > numbers of indentified nematodes
kp <- kp[abund[kp] > id[kp]]

# Simulated size data
cl<-makeCluster(4) # change the 4 to your number of CPU cores
registerDoSNOW(cl) # register the SNOW parallel backend with the foreach package
simu <- foreach(i=kp) %dopar% sample_fun(i)
stopCluster(cl) # stop a SNOW cluster

# Replace with the simulated Nematoda data 
for(i in 1:length(kp)) mei_s[[kp[i]]] <- simu[[i]] 

mei_s <- ldply(mei_s, .id=NULL)

ggplot(data=mei_s, 
       aes(x=log10(Wt), fill=Habitat))+
  geom_density(alpha=0.5)+
  scale_fill_manual(values=c("black", "gray"))+
  facet_grid(Cruise~Category, scale="free")+
  labs(y="Frequency", x=expression(Log[10]~body~size~(mg)))+
  theme_bw() %+replace% large  #%+replace% dark
```

# Environmental data

```{r}
# CTD data
ctd <- as.data.frame(read_excel("../excel/GPSC_CTD_2020.07.23.xlsx", sheet=1))
ctd <- splitBy(~Cruise+Station, ctd)

# Function to get average of bottom 3 deepest CTD data
deep_fun <- function(x) {
   dat <- x[order(x$pressure, decreasing=TRUE)[1:3],]
   summaryBy(.~Cruise+Station, data=dat, keep.names=TRUE, na.rm=TRUE)
}

ctd <- lapply(ctd, FUN=deep_fun)
ctd <- ldply(ctd)[, -1]
ctd$transmissometer[ctd$transmissometer<=0] <- 0 # Set negtive transmissometer to zero

# Average temperature, sigma_theta and density
ctd$Temperature <- rowMeans(ctd[, c("temperature_T1", "temperature_T2")], na.rm=TRUE)
ctd$Salinity <- rowMeans(ctd[, c("salinity_T1C1", "salinity_T2C2")], na.rm=TRUE)
ctd$Sigma_theta <- rowMeans(ctd[, c("density_T1C1...11", "density_T2C2...12")], na.rm=TRUE)
ctd$Density <- rowMeans(ctd[, c("density_T1C1...13", "density_T2C2...14")], na.rm=TRUE)
ctd <- subset(ctd, Cruise=="OR1_1096"|Cruise=="OR1_1102"|Cruise=="OR1_1114"|Cruise=="OR1_1126"|Cruise=="OR1_1128"|(Cruise=="OR1_1132"&Station=="GS1"))
ctd <- ctd[order(ctd$Cruise, ctd$Station),]
ctd <- ctd[, c("Cruise", "Station", "Latitude", "Longitude", "pressure", "Temperature", "Salinity", "Density", "Oxygen", "fluorometer", "transmissometer")]

# Sediment data
col_types <- c(rep("text", 2), "numeric", "text", rep("numeric", 13))
sed <- as.data.frame(read_excel("../excel/GPSC_sediment_2020.06.17.xlsx", sheet=1, col_types=col_types))
sed <- sed[sed$Section=="0-1",]
sed <- subset(sed, Cruise=="OR1_1096"|Cruise=="OR1_1102"|Cruise=="OR1_1114"|Cruise=="OR1_1126"|Cruise=="OR1_1128"|(Cruise=="OR1_1132"&Station=="GS1"))
sed <- sed[order(sed$Cruise, sed$Station),]
sed <- sed[, c("Cruise", "Station", "Deployment", "Section", "Clay", "Silt", "Sand", "CN", "TOC", "TN", "WC", "WW", "DW")]

loc <- read_excel("../excel/GPSC_macro_sorting_2020.07.31.xlsx", sheet=1)
loc <- subset(loc, Cruise=="OR1_1096"|Cruise=="OR1_1102"|Cruise=="OR1_1114"|Cruise=="OR1_1126"|Cruise=="OR1_1128"|(Cruise=="OR1_1132"&Station=="GS1"))
loc <- summaryBy(Longitude+Latitude+Depth~Cruise+Station+Habitat, data=as.data.frame(loc), FUN=mean, keep.names = TRUE)
sed <- cbind(loc, sed[, -1:-3])


# Calculate porosity
# Pore space volume using pore water mass bottom water density
# Fill in seawater desnity for sites not having CTD data 
library(seacarb)

dens <- ctd$Density
vp <- (sed$WW-sed$DW)/(dens/1000)
# Dry sediment volume assuming density of 2.65 g/cm3 
vb <- sed$DW/2.65
sed$Porosity <- vp/(vp+vb)
```


```{r}
save(mac, file="../data/mac.rda")
save(mei, file="../data/mei.rda")
save(mac_s, file="../data/mac_s.rda")
save(mei_s, file="../data/mei_s.rda")
save(ctd, file="../data/ctd.rda")
save(sed, file="../data/sed.rda")
```

